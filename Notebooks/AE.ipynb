{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107dda63",
   "metadata": {},
   "source": [
    "# Autoencoder \n",
    "\n",
    "**Creating an AE that can learn an information rich spectral profiles embeddings to reconstruct the image/spetrum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d0e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('../Data/LPS/LPS_LT_1-1660_x.npy')\n",
    "# intensities of each spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f541a",
   "metadata": {},
   "source": [
    "## Autoencoder Architecture for Mass Spectrometry Data\n",
    "\n",
    "This is the implementation of a baseline **Autoencoder**. The autoencoder learns to encode spectral profiles into a lower-dimensional latent space representation, then reconstructs the original spectra from these compressed embeddings.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "#### 1. **Architecture Design**\n",
    "- **Encoder**: Compresses spectral data from ~1400 peaks → 512 → 256 → 64 latent dimensions\n",
    "- **Decoder**: Reconstructs from 64 latent dimensions → 256 → 512 → 1500 peaks\n",
    "- **Activation Functions**: ReLU for hidden layers, linear output for intensity reconstruction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3904cf70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CategoricalGeneralizedCrossEntropy' from 'keras.src.losses.losses' (/home/vmuser/anaconda3/lib/python3.12/site-packages/keras/src/losses/losses.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSpectrumAutoencoder\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, latent_dim, n_peaks):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28msuper\u001b[39m(SpectrumAutoencoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    205\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.legacy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m   ):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not available with Keras 3.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/_tf_keras/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/_tf_keras/keras/__init__.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m backend\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers \u001b[38;5;28;01mas\u001b[39;00m layers\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses \u001b[38;5;28;01mas\u001b[39;00m losses\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing \u001b[38;5;28;01mas\u001b[39;00m preprocessing\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/_tf_keras/keras/losses/__init__.py:23\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     CategoricalCrossentropy \u001b[38;5;28;01mas\u001b[39;00m CategoricalCrossentropy,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     CategoricalFocalCrossentropy \u001b[38;5;28;01mas\u001b[39;00m CategoricalFocalCrossentropy,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     CategoricalGeneralizedCrossEntropy \u001b[38;5;28;01mas\u001b[39;00m CategoricalGeneralizedCrossEntropy,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalHinge \u001b[38;5;28;01mas\u001b[39;00m CategoricalHinge\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Circle \u001b[38;5;28;01mas\u001b[39;00m Circle\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CategoricalGeneralizedCrossEntropy' from 'keras.src.losses.losses' (/home/vmuser/anaconda3/lib/python3.12/site-packages/keras/src/losses/losses.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "class SpectrumAutoencoder(tf.keras.models.Model):\n",
    "    def __init__(self, latent_dim, n_peaks):\n",
    "        super(SpectrumAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_peaks = n_peaks\n",
    "        \n",
    "        self.encoder = tf.keras.layers.Sequential([\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(latent_dim, activation='relu'),\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(n_peaks, activation='linear'),  \n",
    "        ])\n",
    "\n",
    "    def call(self, intensities):\n",
    "        encoded = self.encoder(intensities)\n",
    "        decoded_intensities = self.decoder(encoded)\n",
    "        return decoded_intensities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d62ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99469ca2",
   "metadata": {},
   "source": [
    "#### 3. **Training Strategy**\n",
    "- **Loss Function**: Mean Squared Error (MSE) for reconstruction fidelity\n",
    "- **Optimization**: Adam optimizer\n",
    "- **Regularization**: Early stopping to prevent overfitting\n",
    "- **Validation**: 80/20 train-test split for performance evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0ab8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1312, 92500)\n",
      "Test set shape: (328, 92500)\n",
      "Input dimension: 92500, Latent dimension: 64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf_keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Latent dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatent_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m SpectrumAutoencoder(latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim, n_peaks\u001b[38;5;241m=\u001b[39minput_dim)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Mean Squared Error for reconstruction\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Mean Absolute Error as additional metric\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mSpectrumAutoencoder.__init__\u001b[0;34m(self, latent_dim, n_peaks)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim \u001b[38;5;241m=\u001b[39m latent_dim\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_peaks \u001b[38;5;241m=\u001b[39m n_peaks\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m tf_keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     17\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     18\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     19\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(latent_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     20\u001b[0m ])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m tf_keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     23\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     24\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     25\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(n_peaks, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m),  \n\u001b[1;32m     26\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_keras' is not defined"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "latent_dim = 64  \n",
    "input_dim = X_train.shape[1]  \n",
    "print(f\"Input dimension: {input_dim}, Latent dimension: {latent_dim}\")\n",
    "\n",
    "autoencoder = SpectrumAutoencoder(latent_dim=latent_dim, n_peaks=input_dim)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',  # Mean Squared Error for reconstruction\n",
    "    metrics=['mae']  # Mean Absolute Error as additional metric\n",
    ")\n",
    "\n",
    "print(f\"Autoencoder created with latent_dim={latent_dim}, input_dim={input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the autoencoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Check data before training\n",
    "print(f\"Training data stats:\")\n",
    "print(f\"  Shape: {X_train.shape}\")\n",
    "print(f\"  Min: {X_train.min():.6f}, Max: {X_train.max():.6f}\")\n",
    "print(f\"  Mean: {X_train.mean():.6f}, Std: {X_train.std():.6f}\")\n",
    "\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = autoencoder.fit(\n",
    "    X_train, X_train,  \n",
    "    epochs=10,  \n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, X_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383bc7d",
   "metadata": {},
   "source": [
    "#### 5. **Evaluation Metrics**\n",
    "- **Reconstruction Error**: MSE and MAE between original and reconstructed spectra\n",
    "- **Visual Assessment**: Direct comparison plots of original vs. reconstructed profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_mae = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n",
    "print(f\"Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original (after preprocessing) vs reconstructed spectra\n",
    "import random\n",
    "def plot_reconstruction_comparison(autoencoder, X_test, common_mzs):\n",
    "    # Plot the 3 random samples vs thier reconstruction\n",
    "    \n",
    "    spectrum1, spectrum2, spectrum3 = random.sample(range(0,len(X_test)),3)\n",
    "    spectra_indexes = [spectrum1,spectrum2,spectrum3]\n",
    "    reconstructed = autoencoder(np.array([X_test[spectrum1],X_test[spectrum2],X_test[spectrum3]]))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 4*3))\n",
    "    \n",
    "    for i in range(3):\n",
    "        axes[i].plot(common_mzs, X_test[spectra_indexes[i]], label='Original', alpha=0.7)\n",
    "        axes[i].plot(common_mzs, reconstructed[i], label='Reconstructed', alpha=0.7)\n",
    "        axes[i].set_xlabel('m/z')\n",
    "        axes[i].set_ylabel('Intensity')\n",
    "        axes[i].set_title(f'Spectrum {i+1} - Reconstruction Comparison')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_reconstruction_comparison(autoencoder, X_test, common_mzs)\n",
    "\n",
    "reconstructed_test = autoencoder(X_test)\n",
    "reconstruction_errors = np.mean(np.square(X_test - reconstructed_test), axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(reconstruction_errors, bins=30, alpha=0.7)\n",
    "plt.xlabel('Reconstruction Error (MSE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reconstruction Errors')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(reconstruction_errors)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error per Sample')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean reconstruction error: {np.mean(reconstruction_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot various recreations of spectra vs each other\n",
    "# plt.plot(common_mzs,X_processed[2])\n",
    "# plt.show()\n",
    "\n",
    "# print(np.array(X_processed[0]))\n",
    "r = autoencoder(np.array([X_processed[0]]))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(common_mzs,r[0])\n",
    "plt.plot(common_mzs,X_processed[0],alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# It seems to be true that there are some spectra that are not reconstrcted well by the AE , e.g index 0,1,2\n",
    "# My hypothesis is that such points have a low amount of the total number of mz actually recorded - high interpolation\n",
    "len(my_spectra[20][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want export an array of the interopolated OG data and the reconstructed data.\n",
    "# print(X_processed.shape)\n",
    "\n",
    "reconstructions = np.array(autoencoder(X_processed))\n",
    "\n",
    "with open(\"HIV_Common_mzs.npy\",'wb') as file:\n",
    "    np.save(file,common_mzs)\n",
    "\n",
    "with open(\"HIV_OG_Normalized.npy\",'wb') as file:\n",
    "    np.save(file,X_processed)\n",
    "\n",
    "with open(\"HIV_Recon_Normalized.npy\",'wb') as file:\n",
    "    np.save(file,reconstructions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(reconstructions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "indexes = []\n",
    "for index in range(len(my_spectra)):\n",
    "    if len(my_spectra[index][0]) < 250:\n",
    "        count+=1\n",
    "        indexes.append(index)\n",
    "print(count)\n",
    "print(len(my_spectra[indexes[3968]][0])) \n",
    "print(indexes[3968])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_mzs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
