Encoder saving started at: Thu Sep 18 09:29:34 PM SAST 2025
Saving encoder for partition 1 of 10 at Thu Sep 18 09:29:34 PM SAST 2025
Start to end indices: (0,21668)
Dataset partitioned into 10 number of chunks
Partition: 1
Training set shape: (15167, 67499)
Validation set shape: (2167, 67499)
Test set shape: (4334, 67499)
Autoencoder created with latent_dim=100, input_dim=67499
Starting training...
Training completed!

Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense (Dense)                   │ (None, 2000)           │   135,000,000 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 2000)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 1000)           │     2,001,000 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 1000)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 100)            │       100,100 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 137,101,100 (523.00 MB)
 Trainable params: 137,101,100 (523.00 MB)
 Non-trainable params: 0 (0.00 B)


[1m  1/136[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m38s[0m 288ms/step[1m  6/136[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 10ms/step  [1m 13/136[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 9ms/step [1m 20/136[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 9ms/step[1m 27/136[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 33/136[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 39/136[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 46/136[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 53/136[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 61/136[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 67/136[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 74/136[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 81/136[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 8ms/step[1m 87/136[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 8ms/step[1m 92/136[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 8ms/step[1m 97/136[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 8ms/step[1m103/136[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 8ms/step[1m108/136[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 9ms/step[1m113/136[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 9ms/step[1m117/136[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 9ms/step[1m121/136[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 9ms/step[1m125/136[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 9ms/step[1m129/136[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 9ms/step[1m133/136[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 9ms/step[1m136/136[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 11ms/step[1m136/136[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 11ms/step
Test Loss: 0.0000210518
Test Loss (MAE): 0.0000884891
Test loss (MSE): 0.0000028928
Mean Absolute Error (MAE) on Test Data: 0.0000884891
Root Mean Squared Error (RMSE) on Test Data: 0.0008986945
Mean Squared Error (MSE) on Test Data: 0.0000028928
Encoder saved to ../Models/AE/encoder_100_dropout_relu_wmse_encoder.keras
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mfloral-firebrand-5[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250918_212955-b7dhith1/logs[0m
Encoder for partition 1 saved at Thu Sep 18 09:38:20 PM SAST 2025
============================================================================
Encoder saving finished at: Thu Sep 18 09:38:20 PM SAST 2025
Tapedza!!! Mwari Ngaakudzwe!
