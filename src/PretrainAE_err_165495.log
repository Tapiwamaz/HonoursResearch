2025-11-01 22:23:28.401361: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 22:23:28.462801: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 22:23:33.071208: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762028621.130220 1883255 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762028621.130952 1883255 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_222342-zczbvtxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-surf-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/zczbvtxs
2025-11-01 22:24:57.022091: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f817800d120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 22:24:57.022646: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 22:24:57.022660: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 22:24:57.207847: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 22:24:57.414826: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762028702.596353 1883620 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:08:46.226353: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:08:46.304734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:08:50.802895: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762031338.877027 1899021 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762031338.877720 1899021 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_230941-o1yn021v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sunset-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/o1yn021v
2025-11-01 23:10:54.930373: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f0e54021ae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:10:54.930877: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:10:54.930884: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:10:55.128100: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:10:55.338195: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762031460.509482 1899384 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:11:10.574148: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:11:10.574208: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:11:10.574229: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:11:10.574244: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:11:10.574257: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:11:10.574269: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574287: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:11:10.574299: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574311: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574327: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:11:10.574339: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574350: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574365: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:11:10.574378: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:11:10.574392: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:11:10.574403: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574440: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:11:10.574451: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574468: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:11:10.574483: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:11:10.574493: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:11:10.574507: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:11:10.574521: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:11:10.574541: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:11:10.574556: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:11:10.574570: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:11:10.574584: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:11:10.574597: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:11:10.574606: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:11:10.574617: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0416000000 of size 2699960064 next 78
2025-11-01 23:11:10.574626: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f04b6ee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:11:10.574634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:11:10.574642: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f09d4000000 of size 2699960064 next 37
2025-11-01 23:11:10.574651: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0a74ee1f00 of size 5118854400 next 38
2025-11-01 23:11:10.574660: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0ba609a400 of size 800000 next 42
2025-11-01 23:11:10.574669: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0ba615d900 of size 40000000 next 43
2025-11-01 23:11:10.574677: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0ba8783300 of size 40192 next 46
2025-11-01 23:11:10.574685: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0ba878d000 of size 40000000 next 47
2025-11-01 23:11:10.574698: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0baadb2a00 of size 800000 next 48
2025-11-01 23:11:10.574707: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0baae75f00 of size 8640000 next 49
2025-11-01 23:11:10.574715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bab6b3500 of size 8640000 next 50
2025-11-01 23:11:10.574724: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0babef0b00 of size 40192 next 57
2025-11-01 23:11:10.574732: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0babefa800 of size 40192 next 55
2025-11-01 23:11:10.574740: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0babf04500 of size 40000000 next 61
2025-11-01 23:11:10.574748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bae529f00 of size 40000000 next 62
2025-11-01 23:11:10.574755: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb0b4f900 of size 800000 next 65
2025-11-01 23:11:10.574764: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb0c12e00 of size 800000 next 66
2025-11-01 23:11:10.574771: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb0cd6300 of size 800000 next 69
2025-11-01 23:11:10.574779: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb0d99800 of size 800000 next 70
2025-11-01 23:11:10.574787: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb0e5cd00 of size 40000000 next 73
2025-11-01 23:11:10.574795: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb3482700 of size 40000000 next 74
2025-11-01 23:11:10.574803: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb5aa8100 of size 40192 next 75
2025-11-01 23:11:10.574811: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bb5ab1e00 of size 40192 next 76
2025-11-01 23:11:10.574819: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f0bb5abbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:11:10.574827: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:11:10.574836: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bde000000 of size 310272 next 34
2025-11-01 23:11:10.574844: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bde04bc00 of size 40192 next 33
2025-11-01 23:11:10.574852: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bde055900 of size 449536 next 25
2025-11-01 23:11:10.574862: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0bde0c3500 of size 79200000 next 19
2025-11-01 23:11:10.574870: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0be2c4b400 of size 40000000 next 18
2025-11-01 23:11:10.574878: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0be5270e00 of size 2699960064 next 22
2025-11-01 23:11:10.574886: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f0c86152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:11:10.574894: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:11:10.574902: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0ce8000000 of size 2699960064 next 30
2025-11-01 23:11:10.574910: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f0d88ee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:11:10.574918: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:11:10.574927: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060400000 of size 1280 next 1
2025-11-01 23:11:10.574936: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060400500 of size 256 next 2
2025-11-01 23:11:10.574949: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060400600 of size 256 next 3
2025-11-01 23:11:10.574957: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060400700 of size 256 next 4
2025-11-01 23:11:10.574965: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060400800 of size 256 next 5
2025-11-01 23:11:10.574973: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060400900 of size 4096 next 23
2025-11-01 23:11:10.574982: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060401900 of size 4096 next 27
2025-11-01 23:11:10.574990: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060402900 of size 4096 next 29
2025-11-01 23:11:10.574998: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060403900 of size 512 next 59
2025-11-01 23:11:10.575007: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060403b00 of size 256 next 53
2025-11-01 23:11:10.575015: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060403c00 of size 256 next 60
2025-11-01 23:11:10.575022: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060403d00 of size 256 next 58
2025-11-01 23:11:10.575031: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060403e00 of size 256 next 54
2025-11-01 23:11:10.575039: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060403f00 of size 4096 next 63
2025-11-01 23:11:10.575047: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060404f00 of size 4096 next 64
2025-11-01 23:11:10.575055: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060405f00 of size 1024 next 67
2025-11-01 23:11:10.575064: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060406300 of size 1024 next 68
2025-11-01 23:11:10.575072: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060406700 of size 4096 next 71
2025-11-01 23:11:10.575079: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060407700 of size 4096 next 72
2025-11-01 23:11:10.575087: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f1060408700 of size 7936 next 9
2025-11-01 23:11:10.575095: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040a600 of size 256 next 6
2025-11-01 23:11:10.575103: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040a700 of size 256 next 7
2025-11-01 23:11:10.575111: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040a800 of size 256 next 12
2025-11-01 23:11:10.575119: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040a900 of size 1024 next 24
2025-11-01 23:11:10.575127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040ad00 of size 256 next 45
2025-11-01 23:11:10.575135: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040ae00 of size 256 next 36
2025-11-01 23:11:10.575143: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040af00 of size 256 next 32
2025-11-01 23:11:10.575151: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040b000 of size 256 next 35
2025-11-01 23:11:10.575159: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040b100 of size 256 next 41
2025-11-01 23:11:10.575168: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040b200 of size 1792 next 14
2025-11-01 23:11:10.575176: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040b900 of size 256 next 17
2025-11-01 23:11:10.575183: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040ba00 of size 256 next 15
2025-11-01 23:11:10.575192: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040bb00 of size 256 next 16
2025-11-01 23:11:10.575204: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040bc00 of size 256 next 28
2025-11-01 23:11:10.575212: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040bd00 of size 256 next 26
2025-11-01 23:11:10.575220: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040be00 of size 256 next 31
2025-11-01 23:11:10.575228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040bf00 of size 256 next 20
2025-11-01 23:11:10.575236: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f106040c000 of size 40192 next 13
2025-11-01 23:11:10.575243: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1060415d00 of size 800000 next 21
2025-11-01 23:11:10.575252: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f10604d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:11:10.575260: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:11:10.575268: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f17ce000000 of size 5118854400 next 40
2025-11-01 23:11:10.575277: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f18ff1b8500 of size 2699960064 next 44
2025-11-01 23:11:10.575285: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f19a009a400 of size 2715363328 next 56
2025-11-01 23:11:10.575294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1a41e2cc00 of size 2699960064 next 52
2025-11-01 23:11:10.575302: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1ae2d0eb00 of size 2699960064 next 51
2025-11-01 23:11:10.575310: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f1b83bf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:11:10.575317: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:11:10.575329: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:11:10.575339: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:11:10.575349: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:11:10.575358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:11:10.575368: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:11:10.575378: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:11:10.575388: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:11:10.575399: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:11:10.575409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:11:10.575419: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:11:10.575429: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:11:10.575439: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:11:10.575450: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:11:10.575460: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:11:10.575470: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:11:10.575480: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:11:10.575494: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:11:10.575505: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:11:10.575515: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:11:10.575530: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:11:10.575554: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:11:10.578205: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
2025-11-01 23:11:14.553655: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:11:14.603634: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:11:18.947391: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762031487.009176 1899943 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762031487.009879 1899943 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_231146-f5n9psfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-flower-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/f5n9psfc
2025-11-01 23:13:00.649128: I external/local_xla/xla/service/service.cc:163] XLA service 0x7fa44401fa80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:13:00.649666: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:13:00.649674: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:13:00.822721: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:13:01.008936: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762031586.136746 1900306 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:13:16.195858: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:13:16.195923: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:13:16.195944: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:13:16.195957: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:13:16.195970: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:13:16.195982: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196009: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:13:16.196021: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196032: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196064: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:13:16.196075: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196085: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196099: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:13:16.196111: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:13:16.196124: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:13:16.196134: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196145: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196159: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:13:16.196169: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196184: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:13:16.196198: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:13:16.196208: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:13:16.196222: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:13:16.196234: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:13:16.196253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:13:16.196274: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:13:16.196288: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:13:16.196301: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:13:16.196313: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:13:16.196322: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:13:16.196333: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f99fe000000 of size 2699960064 next 78
2025-11-01 23:13:16.196341: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f9a9eee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:13:16.196350: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:13:16.196358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9fc8000000 of size 2699960064 next 37
2025-11-01 23:13:16.196366: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa068ee1f00 of size 5118854400 next 38
2025-11-01 23:13:16.196377: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19a09a400 of size 800000 next 42
2025-11-01 23:13:16.196386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19a15d900 of size 40000000 next 43
2025-11-01 23:13:16.196394: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19c783300 of size 40192 next 46
2025-11-01 23:13:16.196402: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19c78d000 of size 40000000 next 47
2025-11-01 23:13:16.196410: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19edb2a00 of size 800000 next 48
2025-11-01 23:13:16.196419: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19ee75f00 of size 8640000 next 49
2025-11-01 23:13:16.196427: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19f6b3500 of size 8640000 next 50
2025-11-01 23:13:16.196435: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19fef0b00 of size 40192 next 57
2025-11-01 23:13:16.196442: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19fefa800 of size 40192 next 55
2025-11-01 23:13:16.196450: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa19ff04500 of size 40000000 next 61
2025-11-01 23:13:16.196458: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a2529f00 of size 40000000 next 62
2025-11-01 23:13:16.196466: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a4b4f900 of size 800000 next 65
2025-11-01 23:13:16.196473: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a4c12e00 of size 800000 next 66
2025-11-01 23:13:16.196481: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a4cd6300 of size 800000 next 69
2025-11-01 23:13:16.196489: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a4d99800 of size 800000 next 70
2025-11-01 23:13:16.196497: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a4e5cd00 of size 40000000 next 73
2025-11-01 23:13:16.196504: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a7482700 of size 40000000 next 74
2025-11-01 23:13:16.196517: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a9aa8100 of size 40192 next 75
2025-11-01 23:13:16.196525: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1a9ab1e00 of size 40192 next 76
2025-11-01 23:13:16.196533: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa1a9abbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:13:16.196540: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:13:16.196549: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d2000000 of size 310272 next 34
2025-11-01 23:13:16.196557: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d204bc00 of size 40192 next 33
2025-11-01 23:13:16.196565: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d2055900 of size 449536 next 25
2025-11-01 23:13:16.196573: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d20c3500 of size 79200000 next 19
2025-11-01 23:13:16.196582: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d6c4b400 of size 40000000 next 18
2025-11-01 23:13:16.196590: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d9270e00 of size 2699960064 next 22
2025-11-01 23:13:16.196599: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa27a152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:13:16.196606: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:13:16.196615: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa2dc000000 of size 2699960064 next 30
2025-11-01 23:13:16.196623: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa37cee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:13:16.196631: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:13:16.196639: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c400000 of size 1280 next 1
2025-11-01 23:13:16.196649: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c400500 of size 256 next 2
2025-11-01 23:13:16.196658: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c400600 of size 256 next 3
2025-11-01 23:13:16.196667: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c400700 of size 256 next 4
2025-11-01 23:13:16.196675: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c400800 of size 256 next 5
2025-11-01 23:13:16.196685: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c400900 of size 4096 next 23
2025-11-01 23:13:16.196694: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c401900 of size 4096 next 27
2025-11-01 23:13:16.196703: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c402900 of size 4096 next 29
2025-11-01 23:13:16.196712: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c403900 of size 512 next 59
2025-11-01 23:13:16.196721: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c403b00 of size 256 next 53
2025-11-01 23:13:16.196730: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c403c00 of size 256 next 60
2025-11-01 23:13:16.196739: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c403d00 of size 256 next 58
2025-11-01 23:13:16.196748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c403e00 of size 256 next 54
2025-11-01 23:13:16.196758: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c403f00 of size 4096 next 63
2025-11-01 23:13:16.196766: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c404f00 of size 4096 next 64
2025-11-01 23:13:16.196779: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c405f00 of size 1024 next 67
2025-11-01 23:13:16.196788: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c406300 of size 1024 next 68
2025-11-01 23:13:16.196796: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c406700 of size 4096 next 71
2025-11-01 23:13:16.196804: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c407700 of size 4096 next 72
2025-11-01 23:13:16.196812: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa64c408700 of size 7936 next 9
2025-11-01 23:13:16.196819: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40a600 of size 256 next 6
2025-11-01 23:13:16.196827: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40a700 of size 256 next 7
2025-11-01 23:13:16.196835: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40a800 of size 256 next 12
2025-11-01 23:13:16.196843: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40a900 of size 1024 next 24
2025-11-01 23:13:16.196850: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40ad00 of size 256 next 45
2025-11-01 23:13:16.196858: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40ae00 of size 256 next 36
2025-11-01 23:13:16.196866: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40af00 of size 256 next 32
2025-11-01 23:13:16.196874: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40b000 of size 256 next 35
2025-11-01 23:13:16.196882: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40b100 of size 256 next 41
2025-11-01 23:13:16.196890: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40b200 of size 1792 next 14
2025-11-01 23:13:16.196898: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40b900 of size 256 next 17
2025-11-01 23:13:16.196906: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40ba00 of size 256 next 15
2025-11-01 23:13:16.196913: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40bb00 of size 256 next 16
2025-11-01 23:13:16.196921: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40bc00 of size 256 next 28
2025-11-01 23:13:16.196929: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40bd00 of size 256 next 26
2025-11-01 23:13:16.196937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40be00 of size 256 next 31
2025-11-01 23:13:16.196945: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40bf00 of size 256 next 20
2025-11-01 23:13:16.196953: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c40c000 of size 40192 next 13
2025-11-01 23:13:16.196960: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c415d00 of size 800000 next 21
2025-11-01 23:13:16.196968: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa64c4d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:13:16.196976: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:13:16.196984: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fadbe000000 of size 5118854400 next 40
2025-11-01 23:13:16.196993: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7faeef1b8500 of size 2699960064 next 44
2025-11-01 23:13:16.197001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7faf9009a400 of size 2715363328 next 56
2025-11-01 23:13:16.197010: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fb031e2cc00 of size 2699960064 next 52
2025-11-01 23:13:16.197018: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fb0d2d0eb00 of size 2699960064 next 51
2025-11-01 23:13:16.197030: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fb173bf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:13:16.197038: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:13:16.197049: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:13:16.197059: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:13:16.197069: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:13:16.197078: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:13:16.197088: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:13:16.197098: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:13:16.197109: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:13:16.197119: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:13:16.197128: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:13:16.197138: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:13:16.197148: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:13:16.197158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:13:16.197169: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:13:16.197179: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:13:16.197189: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:13:16.197199: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:13:16.197208: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:13:16.197219: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:13:16.197228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:13:16.197243: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:13:16.197266: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:13:16.199770: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
2025-11-01 23:13:19.858456: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:13:19.919667: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:13:24.448001: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762031611.820127 1900859 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762031611.820868 1900859 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_231413-0bkrrqi5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-cherry-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/0bkrrqi5
2025-11-01 23:15:26.282252: I external/local_xla/xla/service/service.cc:163] XLA service 0x7fa5b800eec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:15:26.282806: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:15:26.282814: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:15:26.455469: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:15:26.647644: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762031731.759528 1901220 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:15:41.823497: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:15:41.823560: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:15:41.823581: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:15:41.823596: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:15:41.823609: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:15:41.823622: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823638: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:15:41.823650: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823662: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823678: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:15:41.823690: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823701: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823716: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:15:41.823730: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:15:41.823754: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:15:41.823767: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823778: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823793: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:15:41.823804: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823819: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:15:41.823833: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:15:41.823845: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:15:41.823860: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:15:41.823873: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:15:41.823892: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:15:41.823908: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:15:41.823923: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:15:41.823937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:15:41.823949: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:15:41.823958: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:15:41.823970: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9b6e000000 of size 2699960064 next 78
2025-11-01 23:15:41.823979: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f9c0eee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:15:41.823987: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:15:41.823995: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa138000000 of size 2699960064 next 37
2025-11-01 23:15:41.824007: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1d8ee1f00 of size 5118854400 next 38
2025-11-01 23:15:41.824017: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30a09a400 of size 800000 next 42
2025-11-01 23:15:41.824025: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30a15d900 of size 40000000 next 43
2025-11-01 23:15:41.824033: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30c783300 of size 40192 next 46
2025-11-01 23:15:41.824083: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30c78d000 of size 40000000 next 47
2025-11-01 23:15:41.824092: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30edb2a00 of size 800000 next 48
2025-11-01 23:15:41.824100: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30ee75f00 of size 8640000 next 49
2025-11-01 23:15:41.824108: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30f6b3500 of size 8640000 next 50
2025-11-01 23:15:41.824116: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30fef0b00 of size 40192 next 57
2025-11-01 23:15:41.824124: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30fefa800 of size 40192 next 55
2025-11-01 23:15:41.824131: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa30ff04500 of size 40000000 next 61
2025-11-01 23:15:41.824139: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa312529f00 of size 40000000 next 62
2025-11-01 23:15:41.824146: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa314b4f900 of size 800000 next 65
2025-11-01 23:15:41.824154: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa314c12e00 of size 800000 next 66
2025-11-01 23:15:41.824162: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa314cd6300 of size 800000 next 69
2025-11-01 23:15:41.824169: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa314d99800 of size 800000 next 70
2025-11-01 23:15:41.824177: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa314e5cd00 of size 40000000 next 73
2025-11-01 23:15:41.824184: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa317482700 of size 40000000 next 74
2025-11-01 23:15:41.824192: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa319aa8100 of size 40192 next 75
2025-11-01 23:15:41.824200: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa319ab1e00 of size 40192 next 76
2025-11-01 23:15:41.824207: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa319abbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:15:41.824215: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:15:41.824224: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa342000000 of size 310272 next 34
2025-11-01 23:15:41.824232: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa34204bc00 of size 40192 next 33
2025-11-01 23:15:41.824240: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa342055900 of size 449536 next 25
2025-11-01 23:15:41.824249: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa3420c3500 of size 79200000 next 19
2025-11-01 23:15:41.824257: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa346c4b400 of size 40000000 next 18
2025-11-01 23:15:41.824265: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa349270e00 of size 2699960064 next 22
2025-11-01 23:15:41.824272: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa3ea152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:15:41.824280: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:15:41.824294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa44c000000 of size 2699960064 next 30
2025-11-01 23:15:41.824302: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa4ecee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:15:41.824310: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:15:41.824319: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2400000 of size 1280 next 1
2025-11-01 23:15:41.824327: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2400500 of size 256 next 2
2025-11-01 23:15:41.824335: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2400600 of size 256 next 3
2025-11-01 23:15:41.824343: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2400700 of size 256 next 4
2025-11-01 23:15:41.824351: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2400800 of size 256 next 5
2025-11-01 23:15:41.824359: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2400900 of size 4096 next 23
2025-11-01 23:15:41.824367: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2401900 of size 4096 next 27
2025-11-01 23:15:41.824375: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2402900 of size 4096 next 29
2025-11-01 23:15:41.824383: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2403900 of size 512 next 59
2025-11-01 23:15:41.824391: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2403b00 of size 256 next 53
2025-11-01 23:15:41.824399: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2403c00 of size 256 next 60
2025-11-01 23:15:41.824406: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2403d00 of size 256 next 58
2025-11-01 23:15:41.824414: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2403e00 of size 256 next 54
2025-11-01 23:15:41.824421: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2403f00 of size 4096 next 63
2025-11-01 23:15:41.824429: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2404f00 of size 4096 next 64
2025-11-01 23:15:41.824437: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2405f00 of size 1024 next 67
2025-11-01 23:15:41.824445: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2406300 of size 1024 next 68
2025-11-01 23:15:41.824453: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2406700 of size 4096 next 71
2025-11-01 23:15:41.824460: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2407700 of size 4096 next 72
2025-11-01 23:15:41.824468: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa7c2408700 of size 7936 next 9
2025-11-01 23:15:41.824476: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240a600 of size 256 next 6
2025-11-01 23:15:41.824483: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240a700 of size 256 next 7
2025-11-01 23:15:41.824491: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240a800 of size 256 next 12
2025-11-01 23:15:41.824498: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240a900 of size 1024 next 24
2025-11-01 23:15:41.824506: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240ad00 of size 256 next 45
2025-11-01 23:15:41.824513: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240ae00 of size 256 next 36
2025-11-01 23:15:41.824521: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240af00 of size 256 next 32
2025-11-01 23:15:41.824528: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240b000 of size 256 next 35
2025-11-01 23:15:41.824540: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240b100 of size 256 next 41
2025-11-01 23:15:41.824549: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240b200 of size 1792 next 14
2025-11-01 23:15:41.824557: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240b900 of size 256 next 17
2025-11-01 23:15:41.824564: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240ba00 of size 256 next 15
2025-11-01 23:15:41.824572: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240bb00 of size 256 next 16
2025-11-01 23:15:41.824580: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240bc00 of size 256 next 28
2025-11-01 23:15:41.824587: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240bd00 of size 256 next 26
2025-11-01 23:15:41.824595: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240be00 of size 256 next 31
2025-11-01 23:15:41.824603: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240bf00 of size 256 next 20
2025-11-01 23:15:41.824610: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c240c000 of size 40192 next 13
2025-11-01 23:15:41.824618: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c2415d00 of size 800000 next 21
2025-11-01 23:15:41.824626: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa7c24d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:15:41.824634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:15:41.824642: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7faf2e000000 of size 5118854400 next 40
2025-11-01 23:15:41.824650: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fb05f1b8500 of size 2699960064 next 44
2025-11-01 23:15:41.824658: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fb10009a400 of size 2715363328 next 56
2025-11-01 23:15:41.824666: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fb1a1e2cc00 of size 2699960064 next 52
2025-11-01 23:15:41.824674: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fb242d0eb00 of size 2699960064 next 51
2025-11-01 23:15:41.824681: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fb2e3bf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:15:41.824689: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:15:41.824701: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:15:41.824711: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:15:41.824721: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:15:41.824730: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:15:41.824740: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:15:41.824750: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:15:41.824761: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:15:41.824771: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:15:41.824781: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:15:41.824791: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:15:41.824801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:15:41.824815: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:15:41.824826: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:15:41.824836: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:15:41.824846: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:15:41.824855: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:15:41.824865: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:15:41.824876: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:15:41.824885: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:15:41.824901: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:15:41.824923: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:15:41.827513: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
2025-11-01 23:15:45.422038: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:15:45.471752: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:15:50.427552: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762031758.813082 1901776 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762031758.813800 1901776 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_231618-6svb94iq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-cloud-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/6svb94iq
2025-11-01 23:17:32.322643: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f0b4c01fd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:17:32.323197: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:17:32.323205: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:17:32.505221: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:17:32.711515: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762031857.701748 1902139 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:17:47.763018: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:17:47.763085: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:17:47.763108: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:17:47.763134: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:17:47.763150: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:17:47.763162: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763181: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:17:47.763194: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763206: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763223: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:17:47.763235: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763247: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763262: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:17:47.763277: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:17:47.763292: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:17:47.763304: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763316: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763332: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:17:47.763344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763360: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:17:47.763376: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:17:47.763393: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:17:47.763409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:17:47.763425: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:17:47.763447: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:17:47.763464: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:17:47.763480: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:17:47.763495: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:17:47.763510: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:17:47.763520: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:17:47.763533: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f010e000000 of size 2699960064 next 78
2025-11-01 23:17:47.763544: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f01aeee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:17:47.763554: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:17:47.763565: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f06cc000000 of size 2699960064 next 37
2025-11-01 23:17:47.763577: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f076cee1f00 of size 5118854400 next 38
2025-11-01 23:17:47.763590: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f089e09a400 of size 800000 next 42
2025-11-01 23:17:47.763601: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f089e15d900 of size 40000000 next 43
2025-11-01 23:17:47.763611: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a0783300 of size 40192 next 46
2025-11-01 23:17:47.763622: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a078d000 of size 40000000 next 47
2025-11-01 23:17:47.763633: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a2db2a00 of size 800000 next 48
2025-11-01 23:17:47.763646: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a2e75f00 of size 8640000 next 49
2025-11-01 23:17:47.763656: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a36b3500 of size 8640000 next 50
2025-11-01 23:17:47.763665: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a3ef0b00 of size 40192 next 57
2025-11-01 23:17:47.763674: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a3efa800 of size 40192 next 55
2025-11-01 23:17:47.763683: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a3f04500 of size 40000000 next 61
2025-11-01 23:17:47.763691: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a6529f00 of size 40000000 next 62
2025-11-01 23:17:47.763704: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a8b4f900 of size 800000 next 65
2025-11-01 23:17:47.763713: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a8c12e00 of size 800000 next 66
2025-11-01 23:17:47.763722: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a8cd6300 of size 800000 next 69
2025-11-01 23:17:47.763730: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a8d99800 of size 800000 next 70
2025-11-01 23:17:47.763739: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08a8e5cd00 of size 40000000 next 73
2025-11-01 23:17:47.763748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08ab482700 of size 40000000 next 74
2025-11-01 23:17:47.763756: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08adaa8100 of size 40192 next 75
2025-11-01 23:17:47.763765: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08adab1e00 of size 40192 next 76
2025-11-01 23:17:47.763773: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f08adabbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:17:47.763782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:17:47.763792: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08d6000000 of size 310272 next 34
2025-11-01 23:17:47.763802: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08d604bc00 of size 40192 next 33
2025-11-01 23:17:47.763812: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08d6055900 of size 449536 next 25
2025-11-01 23:17:47.763822: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08d60c3500 of size 79200000 next 19
2025-11-01 23:17:47.763831: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08dac4b400 of size 40000000 next 18
2025-11-01 23:17:47.763840: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f08dd270e00 of size 2699960064 next 22
2025-11-01 23:17:47.763849: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f097e152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:17:47.763858: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:17:47.763867: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f09e0000000 of size 2699960064 next 30
2025-11-01 23:17:47.763876: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f0a80ee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:17:47.763884: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:17:47.763895: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a400000 of size 1280 next 1
2025-11-01 23:17:47.763905: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a400500 of size 256 next 2
2025-11-01 23:17:47.763914: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a400600 of size 256 next 3
2025-11-01 23:17:47.763923: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a400700 of size 256 next 4
2025-11-01 23:17:47.763932: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a400800 of size 256 next 5
2025-11-01 23:17:47.763941: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a400900 of size 4096 next 23
2025-11-01 23:17:47.763951: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a401900 of size 4096 next 27
2025-11-01 23:17:47.763960: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a402900 of size 4096 next 29
2025-11-01 23:17:47.763969: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a403900 of size 512 next 59
2025-11-01 23:17:47.763979: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a403b00 of size 256 next 53
2025-11-01 23:17:47.763992: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a403c00 of size 256 next 60
2025-11-01 23:17:47.764000: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a403d00 of size 256 next 58
2025-11-01 23:17:47.764009: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a403e00 of size 256 next 54
2025-11-01 23:17:47.764018: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a403f00 of size 4096 next 63
2025-11-01 23:17:47.764027: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a404f00 of size 4096 next 64
2025-11-01 23:17:47.764036: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a405f00 of size 1024 next 67
2025-11-01 23:17:47.764066: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a406300 of size 1024 next 68
2025-11-01 23:17:47.764075: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a406700 of size 4096 next 71
2025-11-01 23:17:47.764084: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a407700 of size 4096 next 72
2025-11-01 23:17:47.764092: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f0d5a408700 of size 7936 next 9
2025-11-01 23:17:47.764101: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40a600 of size 256 next 6
2025-11-01 23:17:47.764109: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40a700 of size 256 next 7
2025-11-01 23:17:47.764117: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40a800 of size 256 next 12
2025-11-01 23:17:47.764126: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40a900 of size 1024 next 24
2025-11-01 23:17:47.764135: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40ad00 of size 256 next 45
2025-11-01 23:17:47.764144: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40ae00 of size 256 next 36
2025-11-01 23:17:47.764152: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40af00 of size 256 next 32
2025-11-01 23:17:47.764161: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40b000 of size 256 next 35
2025-11-01 23:17:47.764169: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40b100 of size 256 next 41
2025-11-01 23:17:47.764178: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40b200 of size 1792 next 14
2025-11-01 23:17:47.764188: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40b900 of size 256 next 17
2025-11-01 23:17:47.764197: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40ba00 of size 256 next 15
2025-11-01 23:17:47.764205: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40bb00 of size 256 next 16
2025-11-01 23:17:47.764214: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40bc00 of size 256 next 28
2025-11-01 23:17:47.764222: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40bd00 of size 256 next 26
2025-11-01 23:17:47.764231: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40be00 of size 256 next 31
2025-11-01 23:17:47.764240: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40bf00 of size 256 next 20
2025-11-01 23:17:47.764248: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a40c000 of size 40192 next 13
2025-11-01 23:17:47.764256: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a415d00 of size 800000 next 21
2025-11-01 23:17:47.764266: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f0d5a4d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:17:47.764275: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:17:47.764288: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f14ce000000 of size 5118854400 next 40
2025-11-01 23:17:47.764299: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f15ff1b8500 of size 2699960064 next 44
2025-11-01 23:17:47.764308: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f16a009a400 of size 2715363328 next 56
2025-11-01 23:17:47.764318: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f1741e2cc00 of size 2699960064 next 52
2025-11-01 23:17:47.764327: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f17e2d0eb00 of size 2699960064 next 51
2025-11-01 23:17:47.764335: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f1883bf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:17:47.764344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:17:47.764357: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:17:47.764369: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:17:47.764380: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:17:47.764392: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:17:47.764403: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:17:47.764415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:17:47.764427: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:17:47.764440: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:17:47.764452: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:17:47.764464: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:17:47.764475: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:17:47.764488: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:17:47.764500: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:17:47.764512: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:17:47.764524: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:17:47.764536: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:17:47.764547: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:17:47.764560: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:17:47.764570: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:17:47.764588: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:17:47.764616: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:17:47.767219: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
2025-11-01 23:17:51.376494: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:17:51.427474: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:17:56.012457: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762031883.829617 1902692 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762031883.830320 1902692 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_231822-qlj8savq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sun-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/qlj8savq
2025-11-01 23:19:34.330219: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f5b1c00f7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:19:34.330718: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:19:34.330726: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:19:34.509751: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:19:34.708989: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762031979.805460 1903051 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:19:49.869721: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:19:49.869782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:19:49.869803: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:19:49.869817: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:19:49.869830: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:19:49.869842: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.869858: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:19:49.869869: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.869879: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.869895: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:19:49.869906: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.869926: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.869940: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:19:49.869953: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:19:49.869966: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:19:49.869976: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.869987: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.870001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:19:49.870012: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.870026: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:19:49.870041: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:19:49.870052: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:19:49.870066: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:19:49.870078: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:19:49.870098: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:19:49.870113: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:19:49.870127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:19:49.870140: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:19:49.870153: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:19:49.870166: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:19:49.870177: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f50d6000000 of size 2699960064 next 78
2025-11-01 23:19:49.870186: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f5176ee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:19:49.870194: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:19:49.870202: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f56a0000000 of size 2699960064 next 37
2025-11-01 23:19:49.870211: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5740ee1f00 of size 5118854400 next 38
2025-11-01 23:19:49.870221: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587209a400 of size 800000 next 42
2025-11-01 23:19:49.870231: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587215d900 of size 40000000 next 43
2025-11-01 23:19:49.870240: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5874783300 of size 40192 next 46
2025-11-01 23:19:49.870250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587478d000 of size 40000000 next 47
2025-11-01 23:19:49.870258: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5876db2a00 of size 800000 next 48
2025-11-01 23:19:49.870268: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5876e75f00 of size 8640000 next 49
2025-11-01 23:19:49.870278: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58776b3500 of size 8640000 next 50
2025-11-01 23:19:49.870287: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5877ef0b00 of size 40192 next 57
2025-11-01 23:19:49.870295: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5877efa800 of size 40192 next 55
2025-11-01 23:19:49.870303: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5877f04500 of size 40000000 next 61
2025-11-01 23:19:49.870311: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587a529f00 of size 40000000 next 62
2025-11-01 23:19:49.870318: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587cb4f900 of size 800000 next 65
2025-11-01 23:19:49.870326: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587cc12e00 of size 800000 next 66
2025-11-01 23:19:49.870333: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587ccd6300 of size 800000 next 69
2025-11-01 23:19:49.870341: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587cd99800 of size 800000 next 70
2025-11-01 23:19:49.870349: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587ce5cd00 of size 40000000 next 73
2025-11-01 23:19:49.870356: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f587f482700 of size 40000000 next 74
2025-11-01 23:19:49.870364: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5881aa8100 of size 40192 next 75
2025-11-01 23:19:49.870371: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5881ab1e00 of size 40192 next 76
2025-11-01 23:19:49.870379: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f5881abbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:19:49.870386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:19:49.870395: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58aa000000 of size 310272 next 34
2025-11-01 23:19:49.870403: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58aa04bc00 of size 40192 next 33
2025-11-01 23:19:49.870411: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58aa055900 of size 449536 next 25
2025-11-01 23:19:49.870423: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58aa0c3500 of size 79200000 next 19
2025-11-01 23:19:49.870432: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58aec4b400 of size 40000000 next 18
2025-11-01 23:19:49.870439: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f58b1270e00 of size 2699960064 next 22
2025-11-01 23:19:49.870447: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f5952152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:19:49.870454: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:19:49.870462: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f59b4000000 of size 2699960064 next 30
2025-11-01 23:19:49.870470: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f5a54ee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:19:49.870478: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:19:49.870486: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a400000 of size 1280 next 1
2025-11-01 23:19:49.870495: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a400500 of size 256 next 2
2025-11-01 23:19:49.870503: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a400600 of size 256 next 3
2025-11-01 23:19:49.870511: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a400700 of size 256 next 4
2025-11-01 23:19:49.870518: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a400800 of size 256 next 5
2025-11-01 23:19:49.870526: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a400900 of size 4096 next 23
2025-11-01 23:19:49.870534: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a401900 of size 4096 next 27
2025-11-01 23:19:49.870542: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a402900 of size 4096 next 29
2025-11-01 23:19:49.870550: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a403900 of size 512 next 59
2025-11-01 23:19:49.870558: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a403b00 of size 256 next 53
2025-11-01 23:19:49.870565: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a403c00 of size 256 next 60
2025-11-01 23:19:49.870573: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a403d00 of size 256 next 58
2025-11-01 23:19:49.870580: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a403e00 of size 256 next 54
2025-11-01 23:19:49.870588: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a403f00 of size 4096 next 63
2025-11-01 23:19:49.870596: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a404f00 of size 4096 next 64
2025-11-01 23:19:49.870603: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a405f00 of size 1024 next 67
2025-11-01 23:19:49.870611: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a406300 of size 1024 next 68
2025-11-01 23:19:49.870619: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a406700 of size 4096 next 71
2025-11-01 23:19:49.870627: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a407700 of size 4096 next 72
2025-11-01 23:19:49.870634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f5d2a408700 of size 7936 next 9
2025-11-01 23:19:49.870642: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40a600 of size 256 next 6
2025-11-01 23:19:49.870650: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40a700 of size 256 next 7
2025-11-01 23:19:49.870661: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40a800 of size 256 next 12
2025-11-01 23:19:49.870669: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40a900 of size 1024 next 24
2025-11-01 23:19:49.870676: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40ad00 of size 256 next 45
2025-11-01 23:19:49.870684: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40ae00 of size 256 next 36
2025-11-01 23:19:49.870692: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40af00 of size 256 next 32
2025-11-01 23:19:49.870699: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40b000 of size 256 next 35
2025-11-01 23:19:49.870707: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40b100 of size 256 next 41
2025-11-01 23:19:49.870715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40b200 of size 1792 next 14
2025-11-01 23:19:49.870723: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40b900 of size 256 next 17
2025-11-01 23:19:49.870730: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40ba00 of size 256 next 15
2025-11-01 23:19:49.870738: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40bb00 of size 256 next 16
2025-11-01 23:19:49.870746: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40bc00 of size 256 next 28
2025-11-01 23:19:49.870753: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40bd00 of size 256 next 26
2025-11-01 23:19:49.870761: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40be00 of size 256 next 31
2025-11-01 23:19:49.870768: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40bf00 of size 256 next 20
2025-11-01 23:19:49.870776: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a40c000 of size 40192 next 13
2025-11-01 23:19:49.870784: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a415d00 of size 800000 next 21
2025-11-01 23:19:49.870791: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f5d2a4d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:19:49.870799: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:19:49.870807: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f649e000000 of size 5118854400 next 40
2025-11-01 23:19:49.870816: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f65cf1b8500 of size 2699960064 next 44
2025-11-01 23:19:49.870824: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f667009a400 of size 2715363328 next 56
2025-11-01 23:19:49.870832: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6711e2cc00 of size 2699960064 next 52
2025-11-01 23:19:49.870840: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f67b2d0eb00 of size 2699960064 next 51
2025-11-01 23:19:49.870847: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f6853bf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:19:49.870854: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:19:49.870865: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:19:49.870876: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:19:49.870885: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:19:49.870895: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:19:49.870904: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:19:49.870919: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:19:49.870930: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:19:49.870940: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:19:49.870950: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:19:49.870960: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:19:49.870970: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:19:49.870980: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:19:49.870991: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:19:49.871001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:19:49.871012: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:19:49.871021: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:19:49.871030: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:19:49.871041: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:19:49.871051: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:19:49.871066: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:19:49.871088: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:19:49.873593: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
2025-11-01 23:19:53.451564: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:19:53.502146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:19:58.043395: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762032006.061912 1903607 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762032006.062632 1903607 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_232025-9aqn8ocz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-universe-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/9aqn8ocz
2025-11-01 23:21:38.787446: I external/local_xla/xla/service/service.cc:163] XLA service 0x7fd06c00be70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:21:38.787931: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:21:38.787939: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:21:38.981502: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:21:39.166974: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762032104.223227 1903967 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:21:54.284706: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:21:54.284767: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:21:54.284788: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:21:54.284802: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:21:54.284814: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:21:54.284826: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284842: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:21:54.284853: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284863: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284879: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:21:54.284890: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284900: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284914: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:21:54.284927: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:21:54.284941: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:21:54.284952: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284962: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.284976: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:21:54.284996: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.285011: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:21:54.285025: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:21:54.285036: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:21:54.285050: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:21:54.285062: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:21:54.285082: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:21:54.285098: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:21:54.285112: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:21:54.285125: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:21:54.285138: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:21:54.285147: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:21:54.285158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fc626000000 of size 2699960064 next 78
2025-11-01 23:21:54.285167: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fc6c6ee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:21:54.285175: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:21:54.285184: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcbec000000 of size 2699960064 next 37
2025-11-01 23:21:54.285194: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcc8cee1f00 of size 5118854400 next 38
2025-11-01 23:21:54.285204: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdbe09a400 of size 800000 next 42
2025-11-01 23:21:54.285214: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdbe15d900 of size 40000000 next 43
2025-11-01 23:21:54.285223: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc0783300 of size 40192 next 46
2025-11-01 23:21:54.285233: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc078d000 of size 40000000 next 47
2025-11-01 23:21:54.285242: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc2db2a00 of size 800000 next 48
2025-11-01 23:21:54.285251: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc2e75f00 of size 8640000 next 49
2025-11-01 23:21:54.285266: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc36b3500 of size 8640000 next 50
2025-11-01 23:21:54.285275: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc3ef0b00 of size 40192 next 57
2025-11-01 23:21:54.285282: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc3efa800 of size 40192 next 55
2025-11-01 23:21:54.285290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc3f04500 of size 40000000 next 61
2025-11-01 23:21:54.285298: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc6529f00 of size 40000000 next 62
2025-11-01 23:21:54.285306: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc8b4f900 of size 800000 next 65
2025-11-01 23:21:54.285313: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc8c12e00 of size 800000 next 66
2025-11-01 23:21:54.285320: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc8cd6300 of size 800000 next 69
2025-11-01 23:21:54.285328: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc8d99800 of size 800000 next 70
2025-11-01 23:21:54.285336: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdc8e5cd00 of size 40000000 next 73
2025-11-01 23:21:54.285343: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdcb482700 of size 40000000 next 74
2025-11-01 23:21:54.285351: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdcdaa8100 of size 40192 next 75
2025-11-01 23:21:54.285358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdcdab1e00 of size 40192 next 76
2025-11-01 23:21:54.285366: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fcdcdabbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:21:54.285374: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:21:54.285382: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdf6000000 of size 310272 next 34
2025-11-01 23:21:54.285390: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdf604bc00 of size 40192 next 33
2025-11-01 23:21:54.285399: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdf6055900 of size 449536 next 25
2025-11-01 23:21:54.285407: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdf60c3500 of size 79200000 next 19
2025-11-01 23:21:54.285415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdfac4b400 of size 40000000 next 18
2025-11-01 23:21:54.285423: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcdfd270e00 of size 2699960064 next 22
2025-11-01 23:21:54.285431: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fce9e152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:21:54.285439: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:21:54.285446: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fcf00000000 of size 2699960064 next 30
2025-11-01 23:21:54.285455: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fcfa0ee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:21:54.285462: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:21:54.285471: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276400000 of size 1280 next 1
2025-11-01 23:21:54.285479: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276400500 of size 256 next 2
2025-11-01 23:21:54.285487: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276400600 of size 256 next 3
2025-11-01 23:21:54.285495: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276400700 of size 256 next 4
2025-11-01 23:21:54.285507: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276400800 of size 256 next 5
2025-11-01 23:21:54.285515: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276400900 of size 4096 next 23
2025-11-01 23:21:54.285524: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276401900 of size 4096 next 27
2025-11-01 23:21:54.285531: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276402900 of size 4096 next 29
2025-11-01 23:21:54.285539: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276403900 of size 512 next 59
2025-11-01 23:21:54.285547: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276403b00 of size 256 next 53
2025-11-01 23:21:54.285555: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276403c00 of size 256 next 60
2025-11-01 23:21:54.285563: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276403d00 of size 256 next 58
2025-11-01 23:21:54.285571: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276403e00 of size 256 next 54
2025-11-01 23:21:54.285578: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276403f00 of size 4096 next 63
2025-11-01 23:21:54.285587: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276404f00 of size 4096 next 64
2025-11-01 23:21:54.285594: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276405f00 of size 1024 next 67
2025-11-01 23:21:54.285602: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276406300 of size 1024 next 68
2025-11-01 23:21:54.285610: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276406700 of size 4096 next 71
2025-11-01 23:21:54.285618: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276407700 of size 4096 next 72
2025-11-01 23:21:54.285626: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fd276408700 of size 7936 next 9
2025-11-01 23:21:54.285633: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640a600 of size 256 next 6
2025-11-01 23:21:54.285641: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640a700 of size 256 next 7
2025-11-01 23:21:54.285649: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640a800 of size 256 next 12
2025-11-01 23:21:54.285657: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640a900 of size 1024 next 24
2025-11-01 23:21:54.285664: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640ad00 of size 256 next 45
2025-11-01 23:21:54.285671: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640ae00 of size 256 next 36
2025-11-01 23:21:54.285680: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640af00 of size 256 next 32
2025-11-01 23:21:54.285687: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640b000 of size 256 next 35
2025-11-01 23:21:54.285695: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640b100 of size 256 next 41
2025-11-01 23:21:54.285703: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640b200 of size 1792 next 14
2025-11-01 23:21:54.285712: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640b900 of size 256 next 17
2025-11-01 23:21:54.285719: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640ba00 of size 256 next 15
2025-11-01 23:21:54.285727: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640bb00 of size 256 next 16
2025-11-01 23:21:54.285734: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640bc00 of size 256 next 28
2025-11-01 23:21:54.285742: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640bd00 of size 256 next 26
2025-11-01 23:21:54.285754: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640be00 of size 256 next 31
2025-11-01 23:21:54.285762: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640bf00 of size 256 next 20
2025-11-01 23:21:54.285769: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd27640c000 of size 40192 next 13
2025-11-01 23:21:54.285777: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd276415d00 of size 800000 next 21
2025-11-01 23:21:54.285785: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd2764d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:21:54.285793: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:21:54.285800: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fd9e6000000 of size 5118854400 next 40
2025-11-01 23:21:54.285809: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fdb171b8500 of size 2699960064 next 44
2025-11-01 23:21:54.285817: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fdbb809a400 of size 2715363328 next 56
2025-11-01 23:21:54.285825: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fdc59e2cc00 of size 2699960064 next 52
2025-11-01 23:21:54.285833: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fdcfad0eb00 of size 2699960064 next 51
2025-11-01 23:21:54.285841: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fdd9bbf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:21:54.285848: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:21:54.285860: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:21:54.285869: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:21:54.285879: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:21:54.285889: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:21:54.285898: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:21:54.285908: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:21:54.285919: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:21:54.285930: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:21:54.285940: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:21:54.285950: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:21:54.285960: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:21:54.285971: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:21:54.285981: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:21:54.285991: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:21:54.286002: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:21:54.286012: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:21:54.286022: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:21:54.286032: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:21:54.286046: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:21:54.286062: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:21:54.286085: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:21:54.288607: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
2025-11-01 23:21:57.910559: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-01 23:21:57.960485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-11-01 23:22:02.341595: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762032130.356426 1904523 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1762032130.357078 1904523 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251101_232229-9rj73fgh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-bush-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/CorrectAE
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/CorrectAE/runs/9rj73fgh
2025-11-01 23:23:42.578871: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f96f800cbb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-01 23:23:42.579300: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:23:42.579308: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-11-01 23:23:42.765168: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-01 23:23:42.971270: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1762032228.147231 1904886 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-01 23:23:58.211392: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-11-01 23:23:58.211453: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-11-01 23:23:58.211474: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-11-01 23:23:58.211488: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-11-01 23:23:58.211502: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-11-01 23:23:58.211514: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211531: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-11-01 23:23:58.211542: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211563: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211580: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-11-01 23:23:58.211591: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211602: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211617: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-11-01 23:23:58.211630: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-11-01 23:23:58.211644: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-11-01 23:23:58.211655: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211666: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211681: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-11-01 23:23:58.211692: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211707: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-11-01 23:23:58.211722: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-11-01 23:23:58.211733: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-11-01 23:23:58.211748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 15, Chunks in use: 10. 35.66GiB allocated for chunks. 29.67GiB in use in bin. 29.67GiB client-requested in use in bin.
2025-11-01 23:23:58.211760: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-11-01 23:23:58.211780: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 485.27MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-11-01 23:23:58.211796: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.16GiB | Requested Size: 54.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:23:58.211819: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:23:58.211833: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:23:58.211847: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-11-01 23:23:58.211855: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-11-01 23:23:58.211866: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8cd6000000 of size 2699960064 next 78
2025-11-01 23:23:58.211875: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f8d76ee1f00 of size 1613357312 next 18446744073709551615
2025-11-01 23:23:58.211883: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-11-01 23:23:58.211892: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9294000000 of size 2699960064 next 37
2025-11-01 23:23:58.211900: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9334ee1f00 of size 5118854400 next 38
2025-11-01 23:23:58.211911: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946609a400 of size 800000 next 42
2025-11-01 23:23:58.211920: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946615d900 of size 40000000 next 43
2025-11-01 23:23:58.211928: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9468783300 of size 40192 next 46
2025-11-01 23:23:58.211937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946878d000 of size 40000000 next 47
2025-11-01 23:23:58.211945: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946adb2a00 of size 800000 next 48
2025-11-01 23:23:58.211954: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946ae75f00 of size 8640000 next 49
2025-11-01 23:23:58.211962: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946b6b3500 of size 8640000 next 50
2025-11-01 23:23:58.211970: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946bef0b00 of size 40192 next 57
2025-11-01 23:23:58.211977: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946befa800 of size 40192 next 55
2025-11-01 23:23:58.211985: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946bf04500 of size 40000000 next 61
2025-11-01 23:23:58.211993: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f946e529f00 of size 40000000 next 62
2025-11-01 23:23:58.212001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9470b4f900 of size 800000 next 65
2025-11-01 23:23:58.212008: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9470c12e00 of size 800000 next 66
2025-11-01 23:23:58.212016: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9470cd6300 of size 800000 next 69
2025-11-01 23:23:58.212024: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9470d99800 of size 800000 next 70
2025-11-01 23:23:58.212032: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9470e5cd00 of size 40000000 next 73
2025-11-01 23:23:58.212057: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9473482700 of size 40000000 next 74
2025-11-01 23:23:58.212065: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9475aa8100 of size 40192 next 75
2025-11-01 23:23:58.212073: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9475ab1e00 of size 40192 next 76
2025-11-01 23:23:58.212086: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f9475abbb00 of size 508839168 next 18446744073709551615
2025-11-01 23:23:58.212094: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:23:58.212102: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f949e000000 of size 310272 next 34
2025-11-01 23:23:58.212110: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f949e04bc00 of size 40192 next 33
2025-11-01 23:23:58.212119: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f949e055900 of size 449536 next 25
2025-11-01 23:23:58.212127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f949e0c3500 of size 79200000 next 19
2025-11-01 23:23:58.212135: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f94a2c4b400 of size 40000000 next 18
2025-11-01 23:23:58.212143: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f94a5270e00 of size 2699960064 next 22
2025-11-01 23:23:58.212151: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f9546152d00 of size 1475007232 next 18446744073709551615
2025-11-01 23:23:58.212158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-11-01 23:23:58.212167: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f95a8000000 of size 2699960064 next 30
2025-11-01 23:23:58.212175: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f9648ee1f00 of size 1595007232 next 18446744073709551615
2025-11-01 23:23:58.212183: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-11-01 23:23:58.212191: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924400000 of size 1280 next 1
2025-11-01 23:23:58.212201: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924400500 of size 256 next 2
2025-11-01 23:23:58.212209: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924400600 of size 256 next 3
2025-11-01 23:23:58.212216: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924400700 of size 256 next 4
2025-11-01 23:23:58.212224: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924400800 of size 256 next 5
2025-11-01 23:23:58.212233: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924400900 of size 4096 next 23
2025-11-01 23:23:58.212241: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924401900 of size 4096 next 27
2025-11-01 23:23:58.212248: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924402900 of size 4096 next 29
2025-11-01 23:23:58.212256: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924403900 of size 512 next 59
2025-11-01 23:23:58.212264: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924403b00 of size 256 next 53
2025-11-01 23:23:58.212272: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924403c00 of size 256 next 60
2025-11-01 23:23:58.212280: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924403d00 of size 256 next 58
2025-11-01 23:23:58.212287: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924403e00 of size 256 next 54
2025-11-01 23:23:58.212295: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924403f00 of size 4096 next 63
2025-11-01 23:23:58.212303: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924404f00 of size 4096 next 64
2025-11-01 23:23:58.212311: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924405f00 of size 1024 next 67
2025-11-01 23:23:58.212319: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924406300 of size 1024 next 68
2025-11-01 23:23:58.212331: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924406700 of size 4096 next 71
2025-11-01 23:23:58.212339: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924407700 of size 4096 next 72
2025-11-01 23:23:58.212346: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f9924408700 of size 7936 next 9
2025-11-01 23:23:58.212354: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440a600 of size 256 next 6
2025-11-01 23:23:58.212362: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440a700 of size 256 next 7
2025-11-01 23:23:58.212370: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440a800 of size 256 next 12
2025-11-01 23:23:58.212378: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440a900 of size 1024 next 24
2025-11-01 23:23:58.212385: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440ad00 of size 256 next 45
2025-11-01 23:23:58.212393: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440ae00 of size 256 next 36
2025-11-01 23:23:58.212401: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440af00 of size 256 next 32
2025-11-01 23:23:58.212409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440b000 of size 256 next 35
2025-11-01 23:23:58.212416: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440b100 of size 256 next 41
2025-11-01 23:23:58.212425: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440b200 of size 1792 next 14
2025-11-01 23:23:58.212434: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440b900 of size 256 next 17
2025-11-01 23:23:58.212442: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440ba00 of size 256 next 15
2025-11-01 23:23:58.212450: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440bb00 of size 256 next 16
2025-11-01 23:23:58.212459: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440bc00 of size 256 next 28
2025-11-01 23:23:58.212467: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440bd00 of size 256 next 26
2025-11-01 23:23:58.212475: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440be00 of size 256 next 31
2025-11-01 23:23:58.212484: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440bf00 of size 256 next 20
2025-11-01 23:23:58.212492: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f992440c000 of size 40192 next 13
2025-11-01 23:23:58.212500: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f9924415d00 of size 800000 next 21
2025-11-01 23:23:58.212508: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f99244d9200 of size 1207808 next 18446744073709551615
2025-11-01 23:23:58.212516: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-11-01 23:23:58.212524: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa096000000 of size 5118854400 next 40
2025-11-01 23:23:58.212534: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa1c71b8500 of size 2699960064 next 44
2025-11-01 23:23:58.212543: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa26809a400 of size 2715363328 next 56
2025-11-01 23:23:58.212552: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa309e2cc00 of size 2699960064 next 52
2025-11-01 23:23:58.212561: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7fa3aad0eb00 of size 2699960064 next 51
2025-11-01 23:23:58.212569: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7fa44bbf0a00 of size 1245771264 next 18446744073709551615
2025-11-01 23:23:58.212581: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-11-01 23:23:58.212593: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-11-01 23:23:58.212604: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-11-01 23:23:58.212614: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-11-01 23:23:58.212624: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-11-01 23:23:58.212634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-11-01 23:23:58.212645: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-11-01 23:23:58.212657: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-11-01 23:23:58.212668: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-11-01 23:23:58.212680: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-11-01 23:23:58.212691: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-11-01 23:23:58.212703: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-11-01 23:23:58.212715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-11-01 23:23:58.212726: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-11-01 23:23:58.212738: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-11-01 23:23:58.212750: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 2699960064 totalling 17.60GiB
2025-11-01 23:23:58.212760: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363328 totalling 2.53GiB
2025-11-01 23:23:58.212770: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 5118854400 totalling 9.53GiB
2025-11-01 23:23:58.212782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.02GiB
2025-11-01 23:23:58.212791: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-11-01 23:23:58.212807: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32237162752
MaxInUse:                  32237162752
NumAllocs:                         260
MaxAllocSize:               5118854400
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-11-01 23:23:58.212831: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******____******************************___********___******************************************___
2025-11-01 23:23:58.215505: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 168, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/pretrained_ae_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2395]
