2025-10-31 16:01:39.674442: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-31 16:01:39.725891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-10-31 16:01:45.772654: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1761919315.622275 1871495 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1761919315.623430 1871495 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251031_160306-3bqct5hb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spectral-ritual-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/NewPre
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/NewPre/runs/3bqct5hb
2025-10-31 16:13:34.479506: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f715401e420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-10-31 16:13:34.479861: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-10-31 16:13:34.479869: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-10-31 16:13:34.664890: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-10-31 16:13:34.930904: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1761920020.397877 1871855 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-10-31 16:13:50.461125: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-10-31 16:13:50.461204: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-10-31 16:13:50.461226: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-10-31 16:13:50.461240: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-10-31 16:13:50.461253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-10-31 16:13:50.461265: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461283: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-10-31 16:13:50.461294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461306: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461334: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-10-31 16:13:50.461347: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461373: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-10-31 16:13:50.461386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-10-31 16:13:50.461400: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-10-31 16:13:50.461410: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461421: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461436: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-10-31 16:13:50.461447: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461462: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-10-31 16:13:50.461477: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-10-31 16:13:50.461488: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:13:50.461502: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 14, Chunks in use: 9. 35.66GiB allocated for chunks. 30.33GiB in use in bin. 30.33GiB client-requested in use in bin.
2025-10-31 16:13:50.461514: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-10-31 16:13:50.461533: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 296.87MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-10-31 16:13:50.461549: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 697.20MiB | Requested Size: 17.22MiB | in_use: 0 | bin_num: 20, prev:   Size: 8.24MiB | Requested Size: 8.24MiB | in_use: 1 | bin_num: -1
2025-10-31 16:13:50.461563: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:13:50.461582: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:13:50.461596: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 16.12MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:13:50.461604: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-10-31 16:13:50.461616: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6370000000 of size 6824958976 next 39
2025-10-31 16:13:50.461625: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6506cc9c00 of size 6824958976 next 40
2025-10-31 16:13:50.461634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f669d993800 of size 2699960064 next 30
2025-10-31 16:13:50.461643: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f673e875700 of size 800000 next 42
2025-10-31 16:13:50.461651: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f673e938c00 of size 40000000 next 43
2025-10-31 16:13:50.461660: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6740f5e600 of size 40192 next 46
2025-10-31 16:13:50.461668: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6740f68300 of size 40000000 next 47
2025-10-31 16:13:50.461676: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f674358dd00 of size 800000 next 48
2025-10-31 16:13:50.461684: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6743651200 of size 8640000 next 49
2025-10-31 16:13:50.461692: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6743e8e800 of size 8640000 next 50
2025-10-31 16:13:50.461701: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f67446cbe00 of size 731070976 next 18446744073709551615
2025-10-31 16:13:50.461709: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-10-31 16:13:50.461717: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f67d2000000 of size 2699960064 next 54
2025-10-31 16:13:50.461725: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f6872ee1f00 of size 1613357312 next 18446744073709551615
2025-10-31 16:13:50.461733: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-10-31 16:13:50.461741: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6cd0000000 of size 2699960064 next 37
2025-10-31 16:13:50.461749: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6d70ee1f00 of size 2715363584 next 60
2025-10-31 16:13:50.461757: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6e12c74800 of size 2699960064 next 53
2025-10-31 16:13:50.461765: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb3b56700 of size 40192 next 58
2025-10-31 16:13:50.461773: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb3b60400 of size 40192 next 61
2025-10-31 16:13:50.461781: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb3b6a100 of size 40000000 next 62
2025-10-31 16:13:50.461789: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb618fb00 of size 40000000 next 63
2025-10-31 16:13:50.461797: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb87b5500 of size 800000 next 66
2025-10-31 16:13:50.461805: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb8878a00 of size 800000 next 67
2025-10-31 16:13:50.461812: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb893bf00 of size 800000 next 70
2025-10-31 16:13:50.461825: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb89ff400 of size 800000 next 71
2025-10-31 16:13:50.461833: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eb8ac2900 of size 40000000 next 74
2025-10-31 16:13:50.461841: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6ebb0e8300 of size 40000000 next 75
2025-10-31 16:13:50.461848: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6ebd70dd00 of size 40192 next 76
2025-10-31 16:13:50.461856: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6ebd717a00 of size 40192 next 77
2025-10-31 16:13:50.461864: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f6ebd721700 of size 311290112 next 18446744073709551615
2025-10-31 16:13:50.461872: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-10-31 16:13:50.461880: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eda000000 of size 310272 next 34
2025-10-31 16:13:50.461888: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eda04bc00 of size 40192 next 33
2025-10-31 16:13:50.461897: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eda055900 of size 449536 next 25
2025-10-31 16:13:50.461905: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6eda0c3500 of size 79200000 next 19
2025-10-31 16:13:50.461913: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6edec4b400 of size 40000000 next 18
2025-10-31 16:13:50.461921: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6ee1270e00 of size 2699960064 next 22
2025-10-31 16:13:50.461929: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f6f82152d00 of size 1475007232 next 18446744073709551615
2025-10-31 16:13:50.461937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-10-31 16:13:50.461945: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f6fe4000000 of size 2699960064 next 44
2025-10-31 16:13:50.461953: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f7084ee1f00 of size 1595007232 next 18446744073709551615
2025-10-31 16:13:50.461961: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-10-31 16:13:50.461969: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358400000 of size 1280 next 1
2025-10-31 16:13:50.461978: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358400500 of size 256 next 2
2025-10-31 16:13:50.461986: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358400600 of size 256 next 3
2025-10-31 16:13:50.461994: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358400700 of size 256 next 4
2025-10-31 16:13:50.462002: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358400800 of size 256 next 5
2025-10-31 16:13:50.462010: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358400900 of size 4096 next 23
2025-10-31 16:13:50.462019: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358401900 of size 4096 next 27
2025-10-31 16:13:50.462026: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358402900 of size 4096 next 29
2025-10-31 16:13:50.462035: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358403900 of size 512 next 56
2025-10-31 16:13:50.462043: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358403b00 of size 256 next 57
2025-10-31 16:13:50.462050: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358403c00 of size 256 next 59
2025-10-31 16:13:50.462058: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358403d00 of size 256 next 52
2025-10-31 16:13:50.462066: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358403e00 of size 256 next 51
2025-10-31 16:13:50.462078: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358403f00 of size 4096 next 64
2025-10-31 16:13:50.462086: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358404f00 of size 4096 next 65
2025-10-31 16:13:50.462095: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358405f00 of size 1024 next 68
2025-10-31 16:13:50.462103: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358406300 of size 1024 next 69
2025-10-31 16:13:50.462111: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358406700 of size 4096 next 72
2025-10-31 16:13:50.462118: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358407700 of size 4096 next 73
2025-10-31 16:13:50.462126: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f7358408700 of size 7936 next 9
2025-10-31 16:13:50.462134: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840a600 of size 256 next 6
2025-10-31 16:13:50.462142: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840a700 of size 256 next 7
2025-10-31 16:13:50.462150: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840a800 of size 256 next 12
2025-10-31 16:13:50.462158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840a900 of size 1024 next 24
2025-10-31 16:13:50.462165: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840ad00 of size 256 next 45
2025-10-31 16:13:50.462173: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840ae00 of size 256 next 36
2025-10-31 16:13:50.462180: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840af00 of size 256 next 32
2025-10-31 16:13:50.462188: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840b000 of size 256 next 35
2025-10-31 16:13:50.462196: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840b100 of size 256 next 41
2025-10-31 16:13:50.462204: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840b200 of size 1792 next 14
2025-10-31 16:13:50.462213: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840b900 of size 256 next 17
2025-10-31 16:13:50.462221: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840ba00 of size 256 next 15
2025-10-31 16:13:50.462228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840bb00 of size 256 next 16
2025-10-31 16:13:50.462236: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840bc00 of size 256 next 28
2025-10-31 16:13:50.462243: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840bd00 of size 256 next 26
2025-10-31 16:13:50.462251: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840be00 of size 256 next 31
2025-10-31 16:13:50.462259: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840bf00 of size 256 next 20
2025-10-31 16:13:50.462267: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f735840c000 of size 40192 next 13
2025-10-31 16:13:50.462275: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7358415d00 of size 800000 next 21
2025-10-31 16:13:50.462283: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f73584d9200 of size 1207808 next 18446744073709551615
2025-10-31 16:13:50.462290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-10-31 16:13:50.462301: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-10-31 16:13:50.462311: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-10-31 16:13:50.462320: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-10-31 16:13:50.462334: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-10-31 16:13:50.462344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-10-31 16:13:50.462354: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-10-31 16:13:50.462364: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-10-31 16:13:50.462374: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-10-31 16:13:50.462384: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-10-31 16:13:50.462393: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-10-31 16:13:50.462403: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-10-31 16:13:50.462413: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-10-31 16:13:50.462423: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-10-31 16:13:50.462433: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-10-31 16:13:50.462443: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 6 Chunks of size 2699960064 totalling 15.09GiB
2025-10-31 16:13:50.462452: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363584 totalling 2.53GiB
2025-10-31 16:13:50.462462: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 6824958976 totalling 12.71GiB
2025-10-31 16:13:50.462472: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.69GiB
2025-10-31 16:13:50.462481: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-10-31 16:13:50.462497: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32949412096
MaxInUse:                  32949412096
NumAllocs:                         259
MaxAllocSize:               6824958976
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-10-31 16:13:50.462519: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******************************************_********___*******************************__********___*
2025-10-31 16:13:50.465200: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 135, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 135, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2355]
2025-10-31 16:13:54.622316: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-31 16:13:54.675668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-10-31 16:13:58.809577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1761920046.660804 1872333 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1761920046.661512 1872333 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251031_161426-p8i7c1qu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run venomous-nightmare-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/NewPre
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/NewPre/runs/p8i7c1qu
2025-10-31 16:25:02.273619: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f2fd000f710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-10-31 16:25:02.273945: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-10-31 16:25:02.273952: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-10-31 16:25:02.444337: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-10-31 16:25:02.633043: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1761920707.785121 1872695 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-10-31 16:25:17.848852: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-10-31 16:25:17.848920: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-10-31 16:25:17.848956: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-10-31 16:25:17.848977: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-10-31 16:25:17.848996: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-10-31 16:25:17.849013: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849035: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-10-31 16:25:17.849046: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849060: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849080: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-10-31 16:25:17.849096: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849110: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849129: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-10-31 16:25:17.849143: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-10-31 16:25:17.849159: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-10-31 16:25:17.849172: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849185: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849214: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-10-31 16:25:17.849228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849247: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-10-31 16:25:17.849265: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-10-31 16:25:17.849278: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:25:17.849296: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 14, Chunks in use: 9. 35.66GiB allocated for chunks. 30.33GiB in use in bin. 30.33GiB client-requested in use in bin.
2025-10-31 16:25:17.849318: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-10-31 16:25:17.849341: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 296.87MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-10-31 16:25:17.849358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 697.20MiB | Requested Size: 17.22MiB | in_use: 0 | bin_num: 20, prev:   Size: 8.24MiB | Requested Size: 8.24MiB | in_use: 1 | bin_num: -1
2025-10-31 16:25:17.849373: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:25:17.849386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:25:17.849400: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 16.12MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:25:17.849409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-10-31 16:25:17.849423: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f21e8000000 of size 6824958976 next 39
2025-10-31 16:25:17.849434: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f237ecc9c00 of size 6824958976 next 40
2025-10-31 16:25:17.849443: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2515993800 of size 2699960064 next 30
2025-10-31 16:25:17.849451: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25b6875700 of size 800000 next 42
2025-10-31 16:25:17.849459: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25b6938c00 of size 40000000 next 43
2025-10-31 16:25:17.849470: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25b8f5e600 of size 40192 next 46
2025-10-31 16:25:17.849478: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25b8f68300 of size 40000000 next 47
2025-10-31 16:25:17.849486: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25bb58dd00 of size 800000 next 48
2025-10-31 16:25:17.849499: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25bb651200 of size 8640000 next 49
2025-10-31 16:25:17.849510: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f25bbe8e800 of size 8640000 next 50
2025-10-31 16:25:17.849518: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f25bc6cbe00 of size 731070976 next 18446744073709551615
2025-10-31 16:25:17.849525: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-10-31 16:25:17.849533: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2652000000 of size 2699960064 next 54
2025-10-31 16:25:17.849541: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f26f2ee1f00 of size 1613357312 next 18446744073709551615
2025-10-31 16:25:17.849549: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-10-31 16:25:17.849557: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2b48000000 of size 2699960064 next 37
2025-10-31 16:25:17.849564: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2be8ee1f00 of size 2715363584 next 60
2025-10-31 16:25:17.849575: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2c8ac74800 of size 2699960064 next 53
2025-10-31 16:25:17.849583: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d2bb56700 of size 40192 next 58
2025-10-31 16:25:17.849590: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d2bb60400 of size 40192 next 61
2025-10-31 16:25:17.849598: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d2bb6a100 of size 40000000 next 62
2025-10-31 16:25:17.849606: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d2e18fb00 of size 40000000 next 63
2025-10-31 16:25:17.849613: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d307b5500 of size 800000 next 66
2025-10-31 16:25:17.849621: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d30878a00 of size 800000 next 67
2025-10-31 16:25:17.849628: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d3093bf00 of size 800000 next 70
2025-10-31 16:25:17.849636: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d309ff400 of size 800000 next 71
2025-10-31 16:25:17.849643: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d30ac2900 of size 40000000 next 74
2025-10-31 16:25:17.849651: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d330e8300 of size 40000000 next 75
2025-10-31 16:25:17.849658: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d3570dd00 of size 40192 next 76
2025-10-31 16:25:17.849666: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d35717a00 of size 40192 next 77
2025-10-31 16:25:17.849674: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f2d35721700 of size 311290112 next 18446744073709551615
2025-10-31 16:25:17.849681: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-10-31 16:25:17.849689: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d52000000 of size 310272 next 34
2025-10-31 16:25:17.849700: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d5204bc00 of size 40192 next 33
2025-10-31 16:25:17.849708: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d52055900 of size 449536 next 25
2025-10-31 16:25:17.849716: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d520c3500 of size 79200000 next 19
2025-10-31 16:25:17.849724: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d56c4b400 of size 40000000 next 18
2025-10-31 16:25:17.849732: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2d59270e00 of size 2699960064 next 22
2025-10-31 16:25:17.849744: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f2dfa152d00 of size 1475007232 next 18446744073709551615
2025-10-31 16:25:17.849751: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-10-31 16:25:17.849759: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f2e5c000000 of size 2699960064 next 44
2025-10-31 16:25:17.849767: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f2efcee1f00 of size 1595007232 next 18446744073709551615
2025-10-31 16:25:17.849774: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-10-31 16:25:17.849783: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da400000 of size 1280 next 1
2025-10-31 16:25:17.849792: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da400500 of size 256 next 2
2025-10-31 16:25:17.849802: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da400600 of size 256 next 3
2025-10-31 16:25:17.849810: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da400700 of size 256 next 4
2025-10-31 16:25:17.849817: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da400800 of size 256 next 5
2025-10-31 16:25:17.849825: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da400900 of size 4096 next 23
2025-10-31 16:25:17.849835: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da401900 of size 4096 next 27
2025-10-31 16:25:17.849843: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da402900 of size 4096 next 29
2025-10-31 16:25:17.849851: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da403900 of size 512 next 56
2025-10-31 16:25:17.849861: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da403b00 of size 256 next 57
2025-10-31 16:25:17.849868: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da403c00 of size 256 next 59
2025-10-31 16:25:17.849876: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da403d00 of size 256 next 52
2025-10-31 16:25:17.849884: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da403e00 of size 256 next 51
2025-10-31 16:25:17.849891: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da403f00 of size 4096 next 64
2025-10-31 16:25:17.849899: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da404f00 of size 4096 next 65
2025-10-31 16:25:17.849907: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da405f00 of size 1024 next 68
2025-10-31 16:25:17.849915: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da406300 of size 1024 next 69
2025-10-31 16:25:17.849922: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da406700 of size 4096 next 72
2025-10-31 16:25:17.849930: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da407700 of size 4096 next 73
2025-10-31 16:25:17.849937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f31da408700 of size 7936 next 9
2025-10-31 16:25:17.849945: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40a600 of size 256 next 6
2025-10-31 16:25:17.849952: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40a700 of size 256 next 7
2025-10-31 16:25:17.849960: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40a800 of size 256 next 12
2025-10-31 16:25:17.849968: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40a900 of size 1024 next 24
2025-10-31 16:25:17.849975: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40ad00 of size 256 next 45
2025-10-31 16:25:17.849983: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40ae00 of size 256 next 36
2025-10-31 16:25:17.849994: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40af00 of size 256 next 32
2025-10-31 16:25:17.850001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40b000 of size 256 next 35
2025-10-31 16:25:17.850009: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40b100 of size 256 next 41
2025-10-31 16:25:17.850017: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40b200 of size 1792 next 14
2025-10-31 16:25:17.850027: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40b900 of size 256 next 17
2025-10-31 16:25:17.850035: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40ba00 of size 256 next 15
2025-10-31 16:25:17.850043: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40bb00 of size 256 next 16
2025-10-31 16:25:17.850050: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40bc00 of size 256 next 28
2025-10-31 16:25:17.850057: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40bd00 of size 256 next 26
2025-10-31 16:25:17.850065: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40be00 of size 256 next 31
2025-10-31 16:25:17.850073: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40bf00 of size 256 next 20
2025-10-31 16:25:17.850081: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da40c000 of size 40192 next 13
2025-10-31 16:25:17.850088: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da415d00 of size 800000 next 21
2025-10-31 16:25:17.850097: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f31da4d9200 of size 1207808 next 18446744073709551615
2025-10-31 16:25:17.850104: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-10-31 16:25:17.850115: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-10-31 16:25:17.850125: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-10-31 16:25:17.850135: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-10-31 16:25:17.850145: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-10-31 16:25:17.850154: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-10-31 16:25:17.850164: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-10-31 16:25:17.850175: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-10-31 16:25:17.850189: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-10-31 16:25:17.850199: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-10-31 16:25:17.850209: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-10-31 16:25:17.850218: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-10-31 16:25:17.850228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-10-31 16:25:17.850239: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-10-31 16:25:17.850249: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-10-31 16:25:17.850260: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 6 Chunks of size 2699960064 totalling 15.09GiB
2025-10-31 16:25:17.850269: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363584 totalling 2.53GiB
2025-10-31 16:25:17.850284: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 6824958976 totalling 12.71GiB
2025-10-31 16:25:17.850294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.69GiB
2025-10-31 16:25:17.850304: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-10-31 16:25:17.850319: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32949412096
MaxInUse:                  32949412096
NumAllocs:                         259
MaxAllocSize:               6824958976
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-10-31 16:25:17.850344: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******************************************_********___*******************************__********___*
2025-10-31 16:25:17.854901: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 135, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 135, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2355]
2025-10-31 16:25:25.462730: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-31 16:25:25.515348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-10-31 16:25:29.538698: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1761920736.880642 1873169 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36883 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1761920736.881334 1873169 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47155 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:73:00.0, compute capability: 7.5
wandb: Currently logged in as: trapezium (trapezium-wits-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /home-mscluster/tmazarura/HonoursResearch/src/wandb/run-20251031_162556-noq0937d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run endless-fang-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/trapezium-wits-university/NewPre
wandb: üöÄ View run at https://wandb.ai/trapezium-wits-university/NewPre/runs/noq0937d
2025-10-31 16:36:10.601809: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f8dc800e140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-10-31 16:36:10.602361: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2025-10-31 16:36:10.602373: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5
2025-10-31 16:36:10.807206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-10-31 16:36:10.996880: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
I0000 00:00:1761921376.185971 1873531 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-10-31 16:36:26.248364: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.51GiB (rounded to 2699960064)requested by op 
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2025-10-31 16:36:26.248429: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc
2025-10-31 16:36:26.248453: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): 	Total Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 160B client-requested in use in bin.
2025-10-31 16:36:26.248467: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 368B client-requested in use in bin.
2025-10-31 16:36:26.248481: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.1KiB client-requested in use in bin.
2025-10-31 16:36:26.248493: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248521: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): 	Total Chunks: 8, Chunks in use: 7. 35.8KiB allocated for chunks. 28.0KiB in use in bin. 27.3KiB client-requested in use in bin.
2025-10-31 16:36:26.248534: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248545: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248562: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 274.8KiB allocated for chunks. 274.8KiB in use in bin. 273.4KiB client-requested in use in bin.
2025-10-31 16:36:26.248573: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248583: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248598: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 742.0KiB allocated for chunks. 742.0KiB in use in bin. 527.3KiB client-requested in use in bin.
2025-10-31 16:36:26.248611: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): 	Total Chunks: 7, Chunks in use: 7. 5.34MiB allocated for chunks. 5.34MiB in use in bin. 5.34MiB client-requested in use in bin.
2025-10-31 16:36:26.248625: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.15MiB allocated for chunks. 1.15MiB in use in bin. 781.2KiB client-requested in use in bin.
2025-10-31 16:36:26.248636: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248647: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248662: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): 	Total Chunks: 2, Chunks in use: 2. 16.48MiB allocated for chunks. 16.48MiB in use in bin. 16.48MiB client-requested in use in bin.
2025-10-31 16:36:26.248673: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248688: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 267.03MiB allocated for chunks. 267.03MiB in use in bin. 267.03MiB client-requested in use in bin.
2025-10-31 16:36:26.248704: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 75.53MiB allocated for chunks. 75.53MiB in use in bin. 38.15MiB client-requested in use in bin.
2025-10-31 16:36:26.248715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2025-10-31 16:36:26.248729: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): 	Total Chunks: 14, Chunks in use: 9. 35.66GiB allocated for chunks. 30.33GiB in use in bin. 30.33GiB client-requested in use in bin.
2025-10-31 16:36:26.248743: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.51GiB was 256.00MiB, Chunk State: 
2025-10-31 16:36:26.248764: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 296.87MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 39.2KiB | Requested Size: 39.1KiB | in_use: 1 | bin_num: -1
2025-10-31 16:36:26.248786: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 697.20MiB | Requested Size: 17.22MiB | in_use: 0 | bin_num: 20, prev:   Size: 8.24MiB | Requested Size: 8.24MiB | in_use: 1 | bin_num: -1
2025-10-31 16:36:26.248801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.37GiB | Requested Size: 38.15MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:36:26.248815: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.49GiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:36:26.248828: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 1.50GiB | Requested Size: 16.12MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.51GiB | Requested Size: 2.51GiB | in_use: 1 | bin_num: -1
2025-10-31 16:36:26.248837: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 17179869184
2025-10-31 16:36:26.248849: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f7fec000000 of size 6824958976 next 39
2025-10-31 16:36:26.248858: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8182cc9c00 of size 6824958976 next 40
2025-10-31 16:36:26.248866: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8319993800 of size 2699960064 next 30
2025-10-31 16:36:26.248874: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83ba875700 of size 800000 next 42
2025-10-31 16:36:26.248882: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83ba938c00 of size 40000000 next 43
2025-10-31 16:36:26.248891: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83bcf5e600 of size 40192 next 46
2025-10-31 16:36:26.248899: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83bcf68300 of size 40000000 next 47
2025-10-31 16:36:26.248906: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83bf58dd00 of size 800000 next 48
2025-10-31 16:36:26.248914: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83bf651200 of size 8640000 next 49
2025-10-31 16:36:26.248922: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f83bfe8e800 of size 8640000 next 50
2025-10-31 16:36:26.248930: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f83c06cbe00 of size 731070976 next 18446744073709551615
2025-10-31 16:36:26.248938: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4313317376
2025-10-31 16:36:26.248946: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8456000000 of size 2699960064 next 54
2025-10-31 16:36:26.248953: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f84f6ee1f00 of size 1613357312 next 18446744073709551615
2025-10-31 16:36:26.248961: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8589934592
2025-10-31 16:36:26.248969: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f894c000000 of size 2699960064 next 37
2025-10-31 16:36:26.248977: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f89ecee1f00 of size 2715363584 next 60
2025-10-31 16:36:26.248985: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8a8ec74800 of size 2699960064 next 53
2025-10-31 16:36:26.248992: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b2fb56700 of size 40192 next 58
2025-10-31 16:36:26.249000: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b2fb60400 of size 40192 next 61
2025-10-31 16:36:26.249007: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b2fb6a100 of size 40000000 next 62
2025-10-31 16:36:26.249015: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b3218fb00 of size 40000000 next 63
2025-10-31 16:36:26.249026: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b347b5500 of size 800000 next 66
2025-10-31 16:36:26.249034: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b34878a00 of size 800000 next 67
2025-10-31 16:36:26.249041: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b3493bf00 of size 800000 next 70
2025-10-31 16:36:26.249049: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b349ff400 of size 800000 next 71
2025-10-31 16:36:26.249056: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b34ac2900 of size 40000000 next 74
2025-10-31 16:36:26.249063: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b370e8300 of size 40000000 next 75
2025-10-31 16:36:26.249071: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b3970dd00 of size 40192 next 76
2025-10-31 16:36:26.249078: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b39717a00 of size 40192 next 77
2025-10-31 16:36:26.249086: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f8b39721700 of size 311290112 next 18446744073709551615
2025-10-31 16:36:26.249093: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-10-31 16:36:26.249101: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b56000000 of size 310272 next 34
2025-10-31 16:36:26.249109: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b5604bc00 of size 40192 next 33
2025-10-31 16:36:26.249117: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b56055900 of size 449536 next 25
2025-10-31 16:36:26.249125: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b560c3500 of size 79200000 next 19
2025-10-31 16:36:26.249133: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b5ac4b400 of size 40000000 next 18
2025-10-31 16:36:26.249141: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8b5d270e00 of size 2699960064 next 22
2025-10-31 16:36:26.249148: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f8bfe152d00 of size 1475007232 next 18446744073709551615
2025-10-31 16:36:26.249155: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4294967296
2025-10-31 16:36:26.249163: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8c60000000 of size 2699960064 next 44
2025-10-31 16:36:26.249171: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f8d00ee1f00 of size 1595007232 next 18446744073709551615
2025-10-31 16:36:26.249178: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152
2025-10-31 16:36:26.249187: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc400000 of size 1280 next 1
2025-10-31 16:36:26.249196: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc400500 of size 256 next 2
2025-10-31 16:36:26.249204: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc400600 of size 256 next 3
2025-10-31 16:36:26.249211: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc400700 of size 256 next 4
2025-10-31 16:36:26.249219: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc400800 of size 256 next 5
2025-10-31 16:36:26.249227: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc400900 of size 4096 next 23
2025-10-31 16:36:26.249235: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc401900 of size 4096 next 27
2025-10-31 16:36:26.249242: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc402900 of size 4096 next 29
2025-10-31 16:36:26.249250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc403900 of size 512 next 56
2025-10-31 16:36:26.249267: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc403b00 of size 256 next 57
2025-10-31 16:36:26.249275: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc403c00 of size 256 next 59
2025-10-31 16:36:26.249282: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc403d00 of size 256 next 52
2025-10-31 16:36:26.249289: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc403e00 of size 256 next 51
2025-10-31 16:36:26.249297: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc403f00 of size 4096 next 64
2025-10-31 16:36:26.249304: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc404f00 of size 4096 next 65
2025-10-31 16:36:26.249312: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc405f00 of size 1024 next 68
2025-10-31 16:36:26.249320: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc406300 of size 1024 next 69
2025-10-31 16:36:26.249327: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc406700 of size 4096 next 72
2025-10-31 16:36:26.249335: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc407700 of size 4096 next 73
2025-10-31 16:36:26.249342: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7f8fdc408700 of size 7936 next 9
2025-10-31 16:36:26.249350: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40a600 of size 256 next 6
2025-10-31 16:36:26.249357: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40a700 of size 256 next 7
2025-10-31 16:36:26.249364: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40a800 of size 256 next 12
2025-10-31 16:36:26.249372: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40a900 of size 1024 next 24
2025-10-31 16:36:26.249379: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40ad00 of size 256 next 45
2025-10-31 16:36:26.249386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40ae00 of size 256 next 36
2025-10-31 16:36:26.249394: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40af00 of size 256 next 32
2025-10-31 16:36:26.249401: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40b000 of size 256 next 35
2025-10-31 16:36:26.249409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40b100 of size 256 next 41
2025-10-31 16:36:26.249417: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40b200 of size 1792 next 14
2025-10-31 16:36:26.249424: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40b900 of size 256 next 17
2025-10-31 16:36:26.249432: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40ba00 of size 256 next 15
2025-10-31 16:36:26.249439: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40bb00 of size 256 next 16
2025-10-31 16:36:26.249447: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40bc00 of size 256 next 28
2025-10-31 16:36:26.249454: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40bd00 of size 256 next 26
2025-10-31 16:36:26.249461: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40be00 of size 256 next 31
2025-10-31 16:36:26.249469: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40bf00 of size 256 next 20
2025-10-31 16:36:26.249476: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc40c000 of size 40192 next 13
2025-10-31 16:36:26.249484: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc415d00 of size 800000 next 21
2025-10-31 16:36:26.249492: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7f8fdc4d9200 of size 1207808 next 18446744073709551615
2025-10-31 16:36:26.249505: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: 
2025-10-31 16:36:26.249516: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 23 Chunks of size 256 totalling 5.8KiB
2025-10-31 16:36:26.249526: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 512 totalling 512B
2025-10-31 16:36:26.249535: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1024 totalling 3.0KiB
2025-10-31 16:36:26.249545: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB
2025-10-31 16:36:26.249554: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1792 totalling 1.8KiB
2025-10-31 16:36:26.249564: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 4096 totalling 28.0KiB
2025-10-31 16:36:26.249574: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40192 totalling 274.8KiB
2025-10-31 16:36:26.249583: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 310272 totalling 303.0KiB
2025-10-31 16:36:26.249593: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 449536 totalling 439.0KiB
2025-10-31 16:36:26.249602: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 800000 totalling 5.34MiB
2025-10-31 16:36:26.249612: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1207808 totalling 1.15MiB
2025-10-31 16:36:26.249622: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 8640000 totalling 16.48MiB
2025-10-31 16:36:26.249632: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 40000000 totalling 267.03MiB
2025-10-31 16:36:26.249642: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 79200000 totalling 75.53MiB
2025-10-31 16:36:26.249652: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 6 Chunks of size 2699960064 totalling 15.09GiB
2025-10-31 16:36:26.249661: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2715363584 totalling 2.53GiB
2025-10-31 16:36:26.249671: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 6824958976 totalling 12.71GiB
2025-10-31 16:36:26.249681: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 30.69GiB
2025-10-31 16:36:26.249690: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 38675152896 memory_limit_: 38675152896 available bytes: 0 curr_region_allocation_bytes_: 68719476736
2025-10-31 16:36:26.249706: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: 
Limit:                     38675152896
InUse:                     32949412096
MaxInUse:                  32949412096
NumAllocs:                         259
MaxAllocSize:               6824958976
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-10-31 16:36:26.249728: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *******************************************_********___*******************************__********___*
2025-10-31 16:36:26.252426: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

Traceback (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 135, in <module>
    history = autoencoder.fit(
        X_train, X_train,
    ...<4 lines>...
        verbose=0
    )
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    except TypeError as e:
    ...<5 lines>...
      raise e
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File "/home-mscluster/tmazarura/HonoursResearch/src/PretrainAE.py", line 135, in <module>

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 377, in fit

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 220, in function

  File "/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py", line 133, in multi_step_on_iterator

Out of memory while trying to allocate 2699960000 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:   15.33GiB
              constant allocation:         0B
        maybe_live_out allocation:   15.32GiB
     preallocated temp allocation:    2.53GiB
  preallocated temp fragmentation:       192B (0.00%)
                 total allocation:   17.86GiB
Peak buffers:
	Buffer 1:
		Size: 2.51GiB
		Operator: op_type="MatMul" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/MatMul/MatMul_1" source_file="/home-mscluster/tmazarura/miniconda3/lib/python3.13/site-packages/tensorflow/python/framework/ops.py" source_line=1221
		XLA Label: custom-call
		Shape: f32[10000,67499]
		==========================

	Buffer 2:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 3:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 4:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 5:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 6:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,67499]
		==========================

	Buffer 7:
		Size: 2.51GiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[67499,10000]
		==========================

	Buffer 8:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 9:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 10:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 11:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 12:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[1000,10000]
		==========================

	Buffer 13:
		Size: 38.15MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[10000,1000]
		==========================

	Buffer 14:
		Size: 8.24MiB
		Operator: op_type="BiasAddGrad" op_name="gradient_tape/spectrum_autoencoder_1/sequential_1_2/dense_5_1/BiasAdd/BiasAddGrad"
		XLA Label: fusion
		Shape: f32[32,67499]
		==========================

	Buffer 15:
		Size: 8.24MiB
		Operator: op_name="XLA_Args"
		Entry Parameter Subshape: f32[32,67499]
		==========================


	 [[{{node StatefulPartitionedCall}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_multi_step_on_iterator_2355]
